\chapter{Introduction}

In recent years, image-based camera localization has been a key task in the areas of augmented reality, virtual reality, robotics, autonomous driving, etc. In this thesis, we focus on camera localization from RGB images and aim for real-time, efficient, and robust camera localization.

Traditionally, the PnP algorithm \cite{lepetit2009epnp} is used to solve the camera localization problem by computing the 6D camera pose given the 2D and 3D corresponding coordinates of multiple points. The fundamental problems of traditional approaches relying on local image features are textureless environments and robustness against strong changes in illumination/occlusion/viewpoint/etc. between the localized image and the given 3D model. To address these limitations, recently, deep learning has been applied to predict the 2D and 3D coordinates of these control points \cite{brachmann2017dsac} and has achieved superior results. However, these approaches are typically very time-consuming to train and evaluate. In this thesis, we want to combine the benefits of both worlds and develop a learned approach that is efficient and robust.

The problem of 6D object pose estimation from RGB images is related to the problem of camera localization. Recently, an efficient, single-shot approach for simultaneously detecting an object in an RGB image and predicting its 6D pose without requiring multiple stages \cite{tekin2018real} has been proposed. This approach resulted in an improvement over the state-of-the-art in terms of accuracy and efficiency, and addressed the challenges on keypoint occlusion and multiple object pose estimation. In this project, we aim to adapt this approach for efficient image-based camera localization. To this end, we will define keypoints on the 3D room layout for indoor environments and predict the projections of these 3D keypoints. The 6D pose will then be computed using PnP \cite{lepetit2009epnp} based on the correspondences between 2D predictions and 3D reference keypoints.

The major challenges of the project include limited data for training the localization task, occlusion, and motion. To address these issues, one initial idea is to increase the number of keypoints without slowing down the method, which is a direction to go for higher accuracy and robustness. \cite{brachmann2017dsac} provided a trainable RANSAC approach for larger set of control points and can be integrated with the current model. Cutting edge methods could also be learned and utilized to achieve a higher performance.


\section{Motivation}

Image-based camera localization is to compute camera poses under some world coordinate system from images or video captured by the cameras. \cite{wu2018image} In recent years, image-based camera localization has great and wide applications in multiple areas. Autonomous localization and navigation is needed for a moving robot
Augment reality on images: camera pose or localization
View virtual environment: corresponding viewing angle should be computed
Ubiquitous
Relocalization
Real time


\section{Background}

There are many localization tools nowadays, among which GPS is very commonly used outdoors, but it cannot be used indoors. Lidar, UWB, WiFi AP et al are effective indoor localization tools. However, they require special devices or data collection in advance. There are also many methods replying on RGB-D cameras which are quite robust and accurate
Compared to other localization tools, camera localization is the most flexible and low cost one. 

Currently, there are many effective and robust methods relying on depth information acquired by RGB-D cameras. However, the RGB-D cameras are power consuming and not ubiquitous as 2D cameras. Thus, in this work we focus on RGB images that could be acquired by 2D cameras, and do not rely on depth information.

\section{Focus of this work}

\subsection{Example Subsection}

Dummy text.

\subsubsection{Example Subsubsection}

Dummy text.

\paragraph{Example Paragraph}

Dummy text.

\subparagraph{Example Subparagraph}

Dummy text.
